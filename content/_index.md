---
title: "The Uncertainty Toolkit"
date: 2023-03-16
listpages: false
---

A cross-government group has worked together to create a toolkit for assessing and communicating uncertainty.

This toolkit sets out good, not best, practice, as analysis and communication must always be tailored to the audience and decision being made.

The toolkit is presented in the first instance as a suggested set of guidelines and we will be consulting with experts from Government, the academic community and other external bodies to develop thinking in line with the latest evidence on communicating uncertainty.

## Is this toolkit for you?

This toolkit is aimed at all analysts, whether you are new to the Government or an experienced analyst looking to develop the way you communicate uncertainty to stakeholders.

This document sits alongside the Aqua Book guidance on quality analysis. The Aqua Book should be read first as it describes the principles of uncertainty analysis and the processes that should be used in considering it. This is a supplementary document providing additional information for identifying, estimating and communicating uncertainty in analysis to support decisions and decision-makers.

## Uncertainty analysis: understanding what you don’t know

Uncertainty is unavoidable when making predictions about future events or impacts of decisions. Our knowledge of the present is typically incomplete; and we can’t be sure what will happen in the future. We can reduce uncertainty due to lack of knowledge by obtaining more information, or asking experts for advice. However, we can’t eliminate uncertainty entirely, so we must find ways to describe and communicate it.

There is a difference between uncertainty and risk; risk typically refers to the likelihood of a future unplanned event or unintended consequence that can be assigned a numeric probability. Forecasts of risk, like other forecasts, are themselves subject to uncertainty. For example, UK Met Office predictions of the risk of rain are uncertain as to whether it will rain at all, as well as uncertainty about how much it will rain. This uncertainty is described using a range from running several forecasts from equally likely initial conditions.

## Why does it matter?

Taking account of uncertainty – and being seen to do so – is important for public trust. We must not pretend that the consequences of a policy or decision are certain: they are always uncertain to some degree. For each option, a range of outcomes are possible. Implying certainty about one particular outcome can damage public trust when things turn out differently.

### Example: Red River Flood, Grand Forks USA, 1997

The National Weather Service (NWS) predicted, 2 months in advance, the Red River to crest 49 feet.

In response, the levees were built to handle a flood of 51 feet

The actual flood level was 54 feet.

Had the NWS communicated their uncertainty (+/- 9 feet) the several $billion damages as well as the huge personal impact could have been avoided.

<img src="/images/Flood_uncertainty.png" alt="Image showing the predicted and actual flood levels with uncertainty" height="300"/>
<img src="/images/Flood_damage.png" alt="Image of the resulting flood damage" height="300"/>

<br>
<br>

## Toolkit contents

| Chapter | Description | Link | 
|----------|------|--------------|
| 2. Jointly agreeing how uncertainty should be used |  Before conducting any uncertainty analysis, it is important to check that you understand how the analysis will be used. What type of decision is being made? Are you informing a debate or a final decision? This will frame how you approach the analysis and how you communicate it to your customers. | [Jointly agreeing how uncertainty should be used]({{< ref "jointly_agreeing_how_uncertainty_should_be_used">}}) |
| 3. Defining and identifying uncertainty | Considering the whole system that influences your analysis helps identify all possible areas where uncertainty can arise. Ensure you understand what is causing the uncertainty in your inputs and outputs, and whether this can be quantified. | [Defining and identifying uncertainty]({{< ref "defining_and_identifying_uncertainty">}})|
| 4. Mitigating uncertainty |Once uncertainty has been identified it should be reduced where possible. We outline techniques for mitigating uncertainty in a variety of analytical contexts. | [Mitigating uncertainty]({{< ref "mitigating_uncertainty">}})|
| 5. Understanding and measuring uncertainty | Before conducting uncertainty analysis, you should consider the range of possible techniques. We provide a list of the most common techniques with some examples for reference. | [Understanding and measuring uncertainty]({{< ref "understanding_and_measuring_uncertainty">}})|
| 6. Communicating uncertainty | When communicating uncertainty, you should think about how you interact with the audience, tailoring your communication to different groups. This will help them to understand the consequences of uncertainty and why they should be interested in it. | [Communicating uncertainty]({{< ref "communicating_uncertainty">}}) |
| 7. Presenting uncertainty | There is little point conducting any analysis if it has no impact, so this is perhaps the most important section. It is important to engage with your decision makers so they take account of uncertainty in any decisions they make. | [Presenting uncertainty]({{< ref "presenting_uncertainty">}}) |
| 8. Conclusion | A summary of the key messages from the previous pages. | [Conclusion]({{< ref "conclusion">}}) |
| Case Studies | A collection of case studies showing the toolkit's chapters in action. | [Case Studies]({{< ref "case_studies">}}) |
| Further reading | A collection of useful resources including toolkits and guides from other government departments. | [Further reading]({{< ref "further_reading">}}) |

Visit our [Accessibility page]({{< ref "accessibility">}}) for our accessibility statement and additional information about the accessibility of the website.