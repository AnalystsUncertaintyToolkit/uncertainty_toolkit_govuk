---
title: "Defining uncertainty"
date: 2023-02-27T17:25:32Z
draft: false
weight: 1
summary: 
---


There are a number of ways to classify uncertainty. A common classification divides uncertainty into known knowns, known unknowns, and unknown unknowns, as we explain in the table below. [Other classifications (pdf)](https://royalsocietypublishing.org/doi/pdf/10.1098/rsos.181870) consider, for example, the range of things about the analysis which may be uncertain and whether uncertainty relates directly to these “objects” of uncertainty or to the quality of evidence behind them. We recommend following one of these frameworks when assessing the uncertainties that affect your analysis and the decisions it will inform.

<hr>

| Classification  | Aleatory uncertainty | Known unknowns - Epistemic uncertainty | Unknown unknowns - Ontological, Structural and Deep uncertainty* |
| --------------- | ------------------------- | ---------------------------- | -------------------------------- | 
| <strong>Definition</strong>| Sometimes referred to as "known knowns", aleatory uncertainty is the <strong>things we know that we know</strong>. This refers to the inherent uncertainty that is always present due to underlying probabilistic variability. | Known unknowns are <strong>things that we know we don’t know</strong>. This type of uncertainty comes from a lack of knowledge about the (complex) system we are trying to model. Assumptions are used to plug these gaps in the absence of information. | Unknown unknowns are <strong>things that we don't know we don't know </strong>.  It usually comes from factors or situations that we have not previously experienced and therefore, while we can still think about it, we cannot consider it to the same level of detail as other forms of uncertainty. |
| <strong>Can it be quantified? </strong> | <strong>Yes</strong> it can be quantified. We usually characterise it using a probability distribution function (PDF). A PDF gives all the possible values that a variable can have and assigns a probability of occurrence to each. As analysts, the challenge for us is to derive the PDF. If you find that you can’t then you may instead have a known unknown. | <strong>Yes</strong> it can be quantified (but isn’t always) – e.g. through sensitivity analysis. These techniques try to quantify the uncertainty by altering assumptions and observing the impact on modelling outputs. They will work if the range of assumptions tested covers the range of unknown variables. | <strong>No</strong>, although it's likely effect upon our analysis can be qualitatively assessed (see the Evidence Framework Approach outlined in [Glover and Pearce (2020)](https://doi.org/10.1080/17477778.2020.1757389)) through reference to similar things that we do know more about. What we must do is be clear about the sources of uncertainty we have recognised, enabling other sources subsequently identified to likely add to that uncertainty.|
| <strong> Can it be reduced? </strong> | This type of uncertainty cannot be completely removed.  We can sometimes reduce it through data smoothing or increasing the size of a sample, but there will always be some random variability. | Known unknowns are reducible by gathering information to lessen the gaps in our knowledge.  Using new data sources, expanding our data collection or conducting research can remove the need for assumptions or refine their ranges. | This type of uncertainty can usually be reduced through further work, although this may take some time. It can also usefully be separated into “unknowable unknowns” and “knowable unknowns”. Once they are identified they become known unknowns.  |
| <strong> Example </strong> | Tossing a coin is an example of aleatory uncertainty. We can observe the possible outcomes (heads or tails) and the probability of each occurring (50:50), therefore create the PDF. However, prior to the coin being tossed we cannot reduce the uncertainty in outcome. | Taking our coin toss example, we don’t know whether the coin is fair in the first instance. We may assume the coin is fair and will give a 50% probability of each outcome. Once we start to toss the coin, we start to gather information on its fairness. The longer we toss the coin the better our information gets and the greater the reduction in the known unknown. | Unknown unknowns are often future events or circumstances that we cannot predict, for example, somebody swaps the coin to a weighted one without our knowing, or steals the coin altogether! Previous analysis is no longer reliable if it didn’t account for this change. |


*The following definitions can be used to distinguish between these forms of uncertainty:

**Ontological Uncertainty** concerns the degree of conceptual understanding that we have of ‘the world’. Following [Lane (2005)](https://link.springer.com/article/10.1007/s00191-004-0227-7), this leads us to: ‘Grapple’ with the nature of the things we seek to analyse The most appropriate form of their characterisation for a stated purpose The appropriate interpretation of analysis relating to these things See also, [Mingers (2011)](https://doi.org/10.1558/jcr.v10i3.303).

While naively, ontological uncertainty can be said to be unknowable, we can turn this difficulty on its head through engaging with the ongoing challenge to understand the nature of the world around us. A way of achieving this is described in [National Academies of Sciences, Engineering and Medicine (2019, particularly pp 27-54)](https://nap.nationalacademies.org/catalog/25303/reproducibility-and-replicability-in-science).

**Structural Uncertainty** relates to the simplifications we make to derive a ‘concrete’ representation of ‘the world’, from our conceptual understanding, for the purposes of our analysis. Following [Bojke et. al.(2009)](https://linkinghub.elsevier.com/retrieve/pii/S109830151060736X), the focus of structural uncertainty is therefore upon: Relevant models for understanding systemic responses and interactions (which can include internalised mind models and underpinning beliefs, qualitative models and quantitative models) Relevant scenarios, since these represent the factors that shape the response space of a system and either bring or fail to bring key sub-systems into operation. Thus, while Ontological uncertainty focuses on our conceptual characterisation of ‘the world’, structural uncertainty relates to the relevance of our ‘concrete’ or internalised models and scenarios for our analysis.

**Deep Uncertainty** derives from the extent to which we can anticipate the nature of the problem space we will in future need to understand in order to conduct meaningful analysis. Where we cannot anticipate these future circumstances then a judgement is required on when a decision must be made by, with analysis conducted on the best available information to support necessary decision-making. See [Bloemen et. al.(2019)](https://link.springer.com/book/10.1007/978-3-030-05252-2) for analytical approaches.